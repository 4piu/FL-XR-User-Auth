{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the dataset\n",
    "\n",
    "| Column header | Unit of measure | Description |\n",
    "|---------------|-----------------|-------------|\n",
    "| n            | ms             | Timestamp of the recorded gaze sample since the beginning of the recording |\n",
    "| x            | dva            | $\\theta_h$ for the cyclopean eye |\n",
    "| y            | dva            | $\\theta_v$ for the cyclopean eye |\n",
    "| lx           | dva            | $\\theta_h$ for the left eye |\n",
    "| ly           | dva            | $\\theta_v$ for the left eye |\n",
    "| rx           | dva            | $\\theta_h$ for the right eye |\n",
    "| ry           | dva            | $\\theta_v$ for the right eye |\n",
    "| xT*          | dva            | $\\theta_h$ for the stimulus, relative to the cyclopean eye |\n",
    "| yT*          | dva            | $\\theta_v$ for the stimulus, relative to the cyclopean eye |\n",
    "| zT           | m              | Depth of the stimulus |\n",
    "| clx          | m              | X position of the center of the left eyeball, relative to the camera origin |\n",
    "| cly          | m              | Y position of the center of the left eyeball, relative to the camera origin |\n",
    "| clz          | m              | Z position of the center of the left eyeball, relative to the camera origin |\n",
    "| crx          | m              | X position of the center of the right eyeball, relative to the camera origin |\n",
    "| cry          | m              | Y position of the center of the right eyeball, relative to the camera origin |\n",
    "| crz          | m              | Z position of the center of the right eyeball, relative to the camera origin |\n",
    "| round        |                | recording round (1-3) |\n",
    "| participant  |                | participant ID (001-465) |\n",
    "| session      |                | recording session (1-2) |\n",
    "| task         |                | task category (1-5) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "SAMPLE_NUM = 40 # Number of participants to downsample to\n",
    "NUM_OF_MODELS = 10  # Number of models to build based on randomly selected participants\n",
    "TEST_RATIO = 0.2 # Ratio of test data to total data\n",
    "\n",
    "# Sliding window parameters (data sampling @250 Hz)\n",
    "WINDOW_SIZE = 10 * 250 # 10 seconds of data\n",
    "WINDOW_STRIDE = 250 # 1 second stride\n",
    "\n",
    "# Hyperparameters\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_LAYERS = 2\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Output parameters\n",
    "SIGMOID_THRESHOLD = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2287.56 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset using Dask with specified dtypes, filter task PUR\n",
    "df = pd.read_parquet('dataset/gazebasevr.parquet', filters=[('task', '=', 2)])\n",
    "\n",
    "# Exclude metadata columns\n",
    "df = df.drop(columns=['round', 'session', 'task'])\n",
    "\n",
    "# Exclude unfeasible features\n",
    "df = df.drop(columns=['xT', 'yT', 'zT'])\n",
    "\n",
    "# Print memory usage\n",
    "print(f\"{df.memory_usage().sum() / 1024 ** 2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected participants: [272  95 245 105 155 336 414 265 271 170 352 442  65 158  85   2 175 162\n",
      " 229 250 209 370 115 415 388 407 171 219 354 317  58 381 166 429 116 330\n",
      " 301 355 262  10]\n",
      "259.16 MB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Randomly sample 20 participants\n",
    "participants = np.random.choice(df[\"participant\"].unique(), SAMPLE_NUM, replace=False)\n",
    "\n",
    "# Print selected participants\n",
    "print(f\"Selected participants: {participants}\")\n",
    "\n",
    "# Filter the dataset to include only the selected participants\n",
    "df = df[df[\"participant\"].isin(participants)]\n",
    "\n",
    "# Print memory usage\n",
    "print(f\"{df.memory_usage().sum() / 1024 ** 2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    tp = sum((y_true == 1) & (y_pred == 1))\n",
    "    tn = sum((y_true == 0) & (y_pred == 0))\n",
    "    fp = sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = sum((y_true == 1) & (y_pred == 0))\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    return {\n",
    "        \"f1\": f1,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"tp\": tp,\n",
    "        \"tn\": tn,\n",
    "        \"fp\": fp,\n",
    "        \"fn\": fn,\n",
    "    }\n",
    "\n",
    "\n",
    "def split_train_test(df, test_size):\n",
    "    # Ensure the dataframe is sorted by timestamp\n",
    "    df = df.sort_values(by=\"n\")\n",
    "\n",
    "    # Split the data for each participant\n",
    "    train_dfs = []\n",
    "    test_dfs = []\n",
    "\n",
    "    for participant_id, group in df.groupby(\"participant\"):\n",
    "        train, test = train_test_split(group, test_size=test_size, shuffle=False)\n",
    "        train_dfs.append(train)\n",
    "        test_dfs.append(test)\n",
    "\n",
    "    train_df = pd.concat(train_dfs).reset_index(drop=True)\n",
    "    test_df = pd.concat(test_dfs).reset_index(drop=True)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def create_sliding_windows(df, window_size, stride, participant_id):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for pid, group in df.groupby(\"participant\"):\n",
    "        group = group.sort_values(by=\"n\").reset_index(drop=True)\n",
    "        features = group.drop(columns=[\"participant\", \"n\"]).values\n",
    "        label = int(pid == participant_id)\n",
    "\n",
    "        for start in range(0, len(features) - window_size + 1, stride):\n",
    "            window = features[start : start + window_size]\n",
    "            X.append(window)\n",
    "            y.append(label)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def prepare_participant_data(\n",
    "    train_df, test_df, participant_id, window_size, stride\n",
    "):\n",
    "    X_train, y_train = create_sliding_windows(\n",
    "        train_df, window_size, stride, participant_id\n",
    "    )\n",
    "    X_test, y_test = create_sliding_windows(\n",
    "        test_df, window_size, stride, participant_id\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with forward fill and backward fill\n",
    "df = df.ffill().bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "train_df, test_df = split_train_test(df, TEST_RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 3293904\n",
      "Test samples: 823492\n",
      "Ratio: train 0.80, test 0.20\n"
     ]
    }
   ],
   "source": [
    "# Print the number of samples in the training and test set\n",
    "total_samples = len(train_df) + len(test_df)\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "print(f\"Ratio: train {len(train_df) / total_samples:.2f}, test {len(test_df) / total_samples:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>lx</th>\n",
       "      <th>ly</th>\n",
       "      <th>rx</th>\n",
       "      <th>ry</th>\n",
       "      <th>clx</th>\n",
       "      <th>cly</th>\n",
       "      <th>clz</th>\n",
       "      <th>crx</th>\n",
       "      <th>cry</th>\n",
       "      <th>crz</th>\n",
       "      <th>participant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.9118</td>\n",
       "      <td>-4.0018</td>\n",
       "      <td>6.0274</td>\n",
       "      <td>-3.4764</td>\n",
       "      <td>-0.4068</td>\n",
       "      <td>-4.5371</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>-0.0293</td>\n",
       "      <td>0.0327</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>-0.0297</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>-5.7918</td>\n",
       "      <td>2.7773</td>\n",
       "      <td>-5.4001</td>\n",
       "      <td>-2.5670</td>\n",
       "      <td>-6.5306</td>\n",
       "      <td>-0.0331</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>-0.0297</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>-0.0295</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.7793</td>\n",
       "      <td>-0.3799</td>\n",
       "      <td>2.2850</td>\n",
       "      <td>-0.6278</td>\n",
       "      <td>-4.0353</td>\n",
       "      <td>-0.1743</td>\n",
       "      <td>-0.0331</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>-0.0287</td>\n",
       "      <td>0.0327</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>-0.0291</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8193</td>\n",
       "      <td>-4.3130</td>\n",
       "      <td>4.0541</td>\n",
       "      <td>-4.5366</td>\n",
       "      <td>-2.4185</td>\n",
       "      <td>-4.0864</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>-0.0281</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>-0.0293</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.7914</td>\n",
       "      <td>2.9004</td>\n",
       "      <td>-3.9961</td>\n",
       "      <td>5.9637</td>\n",
       "      <td>-3.5508</td>\n",
       "      <td>-0.4068</td>\n",
       "      <td>-4.6690</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>-0.0293</td>\n",
       "      <td>0.0327</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>-0.0297</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n       x       y      lx      ly      rx      ry     clx     cly  \\\n",
       "0  0.0000  2.9118 -4.0018  6.0274 -3.4764 -0.4068 -4.5371 -0.0323  0.0029   \n",
       "1  0.0000  0.0014 -5.7918  2.7773 -5.4001 -2.5670 -6.5306 -0.0331  0.0058   \n",
       "2  0.0000 -0.7793 -0.3799  2.2850 -0.6278 -4.0353 -0.1743 -0.0331  0.0058   \n",
       "3  0.0000  0.8193 -4.3130  4.0541 -4.5366 -2.4185 -4.0864 -0.0323  0.0016   \n",
       "4  3.7914  2.9004 -3.9961  5.9637 -3.5508 -0.4068 -4.6690 -0.0323  0.0029   \n",
       "\n",
       "      clz     crx     cry     crz  participant  \n",
       "0 -0.0293  0.0327  0.0040 -0.0297            2  \n",
       "1 -0.0297  0.0326  0.0078 -0.0295            2  \n",
       "2 -0.0287  0.0327  0.0076 -0.0291            2  \n",
       "3 -0.0281  0.0324  0.0032 -0.0293            2  \n",
       "4 -0.0293  0.0327  0.0041 -0.0297            2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Custom Dataset class\n",
    "class GazeDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = np.array(data)\n",
    "        self.labels = np.array(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx], dtype=torch.float32), torch.tensor(\n",
    "            self.labels[idx], dtype=torch.float32\n",
    "        )\n",
    "\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 0.0972\n",
      "{'f1': 0.842857142857143, 'accuracy': 0.9849004804392587, 'precision': 0.7515923566878981, 'recall': 0.959349593495935, 'tp': np.int64(118), 'tn': np.int64(2752), 'fp': np.int64(39), 'fn': np.int64(5)}\n"
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "participants = np.random.choice(\n",
    "    df[\"participant\"].unique(), NUM_OF_MODELS, replace=False\n",
    ")\n",
    "# participants = [201, 306, 169]\n",
    "print(f\"Models for participants: {participants}\")\n",
    "\n",
    "input_size = train_df.shape[1] - 2  # Exclude participant and n columns\n",
    "\n",
    "results = []\n",
    "\n",
    "for participant_id in participants:\n",
    "    model_path = f\"models/rnn-lstm/{participant_id}.pth\"\n",
    "\n",
    "    if not os.path.exists(\"models/rnn-lstm\"):\n",
    "        os.makedirs(\"models/rnn-lstm\", exist_ok=True)\n",
    "\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Loading model for participant {participant_id} from disk\")\n",
    "        model = LSTMClassifier(input_size, HIDDEN_SIZE, NUM_LAYERS).to(device)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    else:\n",
    "        print(f\"Training model for participant {participant_id}\")\n",
    "        X_train, X_test, y_train, y_test = prepare_participant_data(\n",
    "            train_df, test_df, participant_id, WINDOW_SIZE, WINDOW_STRIDE\n",
    "        )\n",
    "\n",
    "        train_dataset = GazeDataset(X_train, y_train)\n",
    "        test_dataset = GazeDataset(X_test, y_test)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "        # Model, loss function, optimizer\n",
    "        model = LSTMClassifier(input_size, HIDDEN_SIZE, NUM_LAYERS).to(device)\n",
    "\n",
    "        weight_ratio = (len(y_train) - sum(y_train)) / sum(y_train)\n",
    "        pos_weight = torch.tensor([weight_ratio]).to(device)\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            model.train()\n",
    "            for data, labels in tqdm(\n",
    "                train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\", leave=False\n",
    "            ):\n",
    "                data, labels = data.to(device), labels.to(device)\n",
    "                outputs = model(data)\n",
    "                loss = criterion(outputs.squeeze(1), labels)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            IPython.display.clear_output()\n",
    "            print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # Save the model\n",
    "        torch.save(model.state_dict(), f\"models/rnn-lstm/{participant_id}.pth\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    y_true = np.array([])\n",
    "    y_pred = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            outputs = model(data)\n",
    "            predicted = (torch.sigmoid(outputs) > SIGMOID_THRESHOLD).long().squeeze()\n",
    "            y_true = np.concatenate((y_true, labels.cpu().numpy()))\n",
    "            y_pred = np.concatenate((y_pred, predicted.cpu().numpy()))\n",
    "\n",
    "    result = evaluate_model(y_true, y_pred)\n",
    "    print(result)\n",
    "    results.append(result)\n",
    "\n",
    "# Save results\n",
    "if not os.path.exists(\"results\"):\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"results/rnn-lstm.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
