{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the dataset\n",
    "\n",
    "| Column header | Unit of measure | Description |\n",
    "|---------------|-----------------|-------------|\n",
    "| n            | ms             | Timestamp of the recorded gaze sample since the beginning of the recording |\n",
    "| x            | dva            | $\\theta_h$ for the cyclopean eye |\n",
    "| y            | dva            | $\\theta_v$ for the cyclopean eye |\n",
    "| lx           | dva            | $\\theta_h$ for the left eye |\n",
    "| ly           | dva            | $\\theta_v$ for the left eye |\n",
    "| rx           | dva            | $\\theta_h$ for the right eye |\n",
    "| ry           | dva            | $\\theta_v$ for the right eye |\n",
    "| xT*          | dva            | $\\theta_h$ for the stimulus, relative to the cyclopean eye |\n",
    "| yT*          | dva            | $\\theta_v$ for the stimulus, relative to the cyclopean eye |\n",
    "| zT           | m              | Depth of the stimulus |\n",
    "| clx          | m              | X position of the center of the left eyeball, relative to the camera origin |\n",
    "| cly          | m              | Y position of the center of the left eyeball, relative to the camera origin |\n",
    "| clz          | m              | Z position of the center of the left eyeball, relative to the camera origin |\n",
    "| crx          | m              | X position of the center of the right eyeball, relative to the camera origin |\n",
    "| cry          | m              | Y position of the center of the right eyeball, relative to the camera origin |\n",
    "| crz          | m              | Z position of the center of the right eyeball, relative to the camera origin |\n",
    "| round        |                | recording round (1-3) |\n",
    "| participant  |                | participant ID (001-465) |\n",
    "| session      |                | recording session (1-2) |\n",
    "| task         |                | task category (1-5) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2760.84 MB\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset using Dask with specified dtypes, filter task PUR\n",
    "df = pd.read_parquet('dataset/gazebasevr.parquet', filters=[('task', '=', 2)])\n",
    "\n",
    "# Exclude metadata columns\n",
    "df = df.drop(columns=['round', 'session', 'task'])\n",
    "\n",
    "# Print memory usage\n",
    "print(f\"{df.memory_usage().sum() / 1024 ** 2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159.38 MB\n"
     ]
    }
   ],
   "source": [
    "NUM_PARTICIPANTS = 20\n",
    "\n",
    "# Randomly sample 20 participants\n",
    "participants = df['participant'].unique()\n",
    "participants = participants[:NUM_PARTICIPANTS]\n",
    "\n",
    "# Filter the dataset to include only the selected participants\n",
    "df = df[df['participant'].isin(participants)]\n",
    "\n",
    "# Print memory usage\n",
    "print(f\"{df.memory_usage().sum() / 1024 ** 2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with forward fill and backward fill\n",
    "df = df.ffill().bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for participant 2, rows: 165051\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "              <p>\n",
       "                  Progress: 0% Complete\n",
       "              <p/>\n",
       "              <progress\n",
       "                  value='0'\n",
       "                  max='66',\n",
       "                  style='width: 25%',\n",
       "              >\n",
       "                  0\n",
       "              </progress>\n",
       "\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import IPython\n",
    "import tsfel\n",
    "import os\n",
    "\n",
    "DATA_FREQUENCY = 250\n",
    "WINDOW_SIZE = 10 * DATA_FREQUENCY # 10 seconds\n",
    "\n",
    "# For each participant in the dataset, extract features for that participant\n",
    "results = []\n",
    "for participant_id, group in df.groupby(\"participant\"):\n",
    "    IPython.display.clear_output(wait=True)\n",
    "    print(f\"Extracting features for participant {participant_id}, rows: {len(group)}\")\n",
    "\n",
    "    cache_file = f\"cache/tsfel/{participant_id}.parquet\"\n",
    "    # create cache directory if not exists\n",
    "    os.makedirs(os.path.dirname(cache_file), exist_ok=True)\n",
    "    if os.path.exists(cache_file):\n",
    "        features = pd.read_parquet(cache_file)\n",
    "    else:\n",
    "        # Extract features with TSFEL\n",
    "        cfg = tsfel.get_features_by_domain()\n",
    "        # https://github.com/fraunhoferportugal/tsfel/issues/173\n",
    "        features = tsfel.time_series_features_extractor(\n",
    "            cfg, group.drop(columns=[\"n\", \"participant\"]), fs=DATA_FREQUENCY, window_size=WINDOW_SIZE, n_jobs=-1\n",
    "        )\n",
    "        features.to_parquet(cache_file)\n",
    "\n",
    "    features[\"participant\"] = participant_id\n",
    "    results.append(features)\n",
    "\n",
    "features_df = pd.concat(results).reset_index(drop=True)\n",
    "# Save the extracted features\n",
    "features_df.to_parquet(f\"cache/gazebasevr-features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print shape of the extracted features\n",
    "print(f\"Dataset shape: {features_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
